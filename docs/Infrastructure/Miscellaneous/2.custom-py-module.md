---
sidebar_position: 2
---

# Create Custom Python Module and Distribute with Git

When we create a custom Python module, we can distribute it through a Git repository. By using a private repo, you can keep your module private and use it in your deployment pipeline by calling pip install from the private repo. Pretty cool trick.

In this example, I created a simple Python module to do S3 download and upload and pushed it to a Git repo for pip installation.

First of all, we need to have the right folder structure with setup.py.

The folder structure will look like:

```bash
s3uploader
    - README.txt
    - LICENSE.txt
    - setup.py
    - s3uploader
        - s3.py
        - __init__.py
```

The key is to have the correct setup.py file. This describes the metadata about the module as well as is used for installation.

setup.py

from distutils.core import setup

```
setup(
    name='S3Uploader',
    version='0.1demo',
    packages=['s3uploader',],
    license='Creative Commons Attribution-Noncommercial-Share Alike license',
    long_description=open('README.txt').read(),
    url='https://github.com/mydatahack/s3uploader'
)
```

The top level project folder is the name of the module. There is another folder with the same name, including **init**.py and actual python code that contains the class.

The init file references the class that can be imported by the module.

```python
__init__.py

from .s3 import S3
```

Here is the actual S3 class that does upload and download.

s3.py

```python
import boto3

class S3:
    """
    S3 class with upload and download methods
    For Python package demo
    """

    def __init__ (self, bucket, key, local_file):
        """Initialising s3 object with bucket & key"""
        self.bucket = bucket
        self.key = key
        self.local_file = local_file
        self.s3 = boto3.resource('s3')
        self.s3_path = bucket + '/' + key

    def upload(self):
        """Upload file from local machine"""
        print('Uploading {} to {}'.format(self.local_file, self.s3_path))
        self.s3.meta.client.upload_file(self.local_file, self.bucket, self.key)
        print('Upload Completed')

    def download(self):
        """Download file to local machine"""
        print('Downloading {} to {}'.format(self.s3_path, self.local_file))
        self.s3.Bucket(self.bucket).download_file(self.key, self.local_file)
        print('Download Completed')
```

Once everything is done, letâ€™s push it to the repo and all done. Installation is easy. You can pass the repo url in pip install as below.

Installation

pip install git+https://github.com/mydatahack/s3uploader
You can now test the module.

from s3uploader import S3

```python
bucket= 'your.bucket.name'
key = 'data/transaction.json'
local_file = '/tmp/transaction.json'
s3Upload = S3(bucket, key, local_file)

s3Upload.upload()

local_file = './transaction.json'
s3Download = S3(bucket, key, local_file)

s3Download.download()
```

(2018-09-26)
